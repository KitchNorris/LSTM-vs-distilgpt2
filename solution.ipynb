{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые модули проекта и библиотеки\n",
    "from src.data_utils import dataset_cleaner\n",
    "from src import next_token_dataset\n",
    "from src.next_token_dataset import get_datasets, collate_fn\n",
    "from src.lstm_model import LSTMTokenPredictor\n",
    "from src.lstm_model_att import LSTMAttentionTokenPredictor, LSTMCausalAttentionPredictor\n",
    "#from src.lstm_train import training_loop\n",
    "from src.lstm_train_up import training_loop\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55bcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем и чистим исходный текст, сохраняем очищенный датасет\n",
    "dataset_cleaner(\"data/tweets.txt\", \"data/tweets_cleaned.csv\", 500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b94a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем токенизатор (подберите подходящий для вашего языка и задачи)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Получаем токенезированные датасеты\n",
    "train_dataset, val_dataset = get_datasets(tokenizer, 'data/tweets_cleaned_small.csv')\n",
    "\n",
    "# Создаём DataLoader'ы\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, collate_fn=collate_fn, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb33b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размер словаря\n",
    "vocab_size = tokenizer.vocab_size \n",
    "\n",
    "# Создаем объект модели\n",
    "#model = LSTMTokenPredictor(vocab_size=vocab_size)\n",
    "#model = LSTMAttentionTokenPredictor(vocab_size=vocab_size)\n",
    "model = LSTMCausalAttentionPredictor(vocab_size=vocab_size)\n",
    "\n",
    "# Запускаем обучение модели \n",
    "train_losses, val_losses, rouge_scores = training_loop(model, tokenizer, train_loader, val_loader, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dcf394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отрисовка графиков\n",
    "\n",
    "epochs = np.arange(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# --- Левая ось: train / val loss ---\n",
    "plt.plot(epochs, train_losses, label='Train Loss', color='tab:blue', marker='o')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss', color='tab:orange', marker='o')\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\", color='tab:blue')\n",
    "plt.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# --- Правая ось: ROUGE ---\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(epochs, rouge_scores, label='ROUGE-1', color='tab:green', marker='s')\n",
    "ax2.set_ylabel(\"ROUGE-1\", color='tab:green')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:green')\n",
    "\n",
    "# --- Общее оформление ---\n",
    "plt.title(\"Training Progress: Loss and ROUGE-1 per Epoch\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Совмещённая легенда для обеих осей\n",
    "lines, labels = plt.gca().get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "plt.legend(lines + lines2, labels + labels2, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24fe4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка датасета/даталоадера для трансформера\n",
    "from src.dist_gpt import prepare_gpt_tokenizer, load_gpt_model, evaluate_transformer_rouge\n",
    "from src.next_token_dataset import PredictDataset, collate_fn, choose_max_len\n",
    "import pandas as pd\n",
    "\n",
    "# Загружаем токенизатор GPT-2\n",
    "tokenizer = prepare_gpt_tokenizer(\"distilgpt2\")\n",
    "\n",
    "# Загружаем тестовый датасет из ранее сохранённого CSV\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# Получаем ту же max_len, что при обучении LSTM (можно захардкодить, если известно)\n",
    "max_len = choose_max_len(test_df[\"clean_text\"].dropna().astype(str).tolist())\n",
    "\n",
    "# Создаём датасет\n",
    "test_dataset = PredictDataset(test_df[\"clean_text\"].tolist(), tokenizer, max_len)\n",
    "\n",
    "# DataLoader\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,  # чуть меньше, чтобы не перегружать память GPT-2\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbee600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval transformer ROUGE:   0%|          | 0/3110 [00:00<?, ?it/s]c:\\Users\\smoly\\OneDrive\\Рабочий стол\\Курс DL\\.fpenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Transformer\n",
    "\n",
    "model = load_gpt_model(\"distilgpt2\")\n",
    "results, preds, refs = evaluate_transformer_rouge(model, tokenizer, test_loader,\n",
    "                                                 sample_limit=None,\n",
    "                                                 generation_kwargs=dict(temperature=0.8, top_k=50, top_p=0.95, do_sample=True),\n",
    "                                                 verbose_examples=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".fpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
